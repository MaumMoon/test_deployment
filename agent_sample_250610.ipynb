{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e967922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonyoung/anaconda3/envs/gemini-langchain/lib/python3.13/site-packages/numpy/_core/getlimits.py:551: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n",
      "/home/moonyoung/anaconda3/envs/gemini-langchain/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151df2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../')\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e227621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=200,\n",
    "    google_api_key=GEMINI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3777c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./maum_ai_product_sample.xlsx\")\n",
    "loader = DataFrameLoader(df, page_content_column=\"설명\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9bd02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14432abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-exp-03-07\", google_api_key=GEMINI_API_KEY)\n",
    "vectorstore = Chroma.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442db8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5c78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"\n",
    "    Given a chat history and the latest user question which might reference context in the chat history,\n",
    "    formulate a standalone question which can be understood without the chat history.\n",
    "    Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca5aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseGenerator():\n",
    "    def __init__(self):\n",
    "        self.template = \"\"\n",
    "        self.ragchain = self.rag_chain_generator()\n",
    "        self.store = {}\n",
    "\n",
    "    def template_generator(self):\n",
    "        template = \"\"\"\n",
    "                당신은 이 회사의 상품을 추천하는 임부를 부여받았습니다.\n",
    "                고객들은 당신에게 AI가 필요한 특정 상황을 설명할 것입니다.\n",
    "                당신은 고객 문의에 대해 단계별로 차근차근 친절하게 설명해 주세요.\n",
    "                없는 정보는 답하면 안 됩니다.\n",
    "                반드시 회사 상품 하나를 추천해야 합니다.\n",
    "                끝에는 언제나 '감사합니다!'라는 멘트를 붙여주세요.\n",
    "                \\n\\n\n",
    "                {context}\n",
    "                질문: {input}\n",
    "                You MUST answer in Korean:\n",
    "                \"\"\"\n",
    "        return template\n",
    "    \n",
    "    def prompt_generator(self):\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.template_generator()),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        return prompt\n",
    "    \n",
    "    def rag_chain_generator(self):\n",
    "        question_answer_chain = create_stuff_documents_chain(\n",
    "            llm, self.prompt_generator()\n",
    "        )\n",
    "\n",
    "        history_aware_retriever = create_history_aware_retriever(\n",
    "            llm, retriever, contextualize_q_prompt\n",
    "        )\n",
    "\n",
    "        rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "        \n",
    "        return RunnableWithMessageHistory(\n",
    "            rag_chain,\n",
    "            self.get_session_history,\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "            output_messages_key=\"answer\"\n",
    "            )\n",
    "    \n",
    "    def get_session_history(self, session_ids):\n",
    "        if session_ids not in self.store:  \n",
    "            self.store[session_ids] = ChatMessageHistory()\n",
    "        return self.store[session_ids]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53221435",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = ResponseGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d4af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_from_llm(text, session_id):\n",
    "    rag_chain = rg.ragchain\n",
    "    \n",
    "    result = rag_chain.invoke(\n",
    "        {\"input\": text}, \n",
    "            config = {\"configurable\": {\"session_id\": session_id}}\n",
    "    )[\"answer\"]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09dcfd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 자율주행 AI에 대해 문의하셨군요.  자세히 말씀해주시면 제가 도와드리겠습니다. 어떤 부분에 대해 궁금하신가요? 예를 들어, 자율주행 AI의 작동 원리,  적용 분야,  구축 방법 등 구체적으로 질문해주시면 더욱 정확한 답변을 드릴 수 있습니다.\\n\\n하지만 혹시 시각 정보 기반의 End-to-End 자율주행에 관심이 있으신가요?  그렇다면 저희 회사의 **E2E Autonomous Driving Kit**를 추천드립니다.\\n\\n이 키트는 다음과 같은 장점을 가지고 있습니다.\\n\\n1. **시각 정보 기반:** 카메라 등 시각 정보만을 이용하여 주변 환경을 인식하고'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_from_llm('자율주행 ai에 대해 문의하고 싶어요.', 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
